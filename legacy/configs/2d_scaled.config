
model {
  input_image_size_x: 256
  input_image_size_y: 256
  input_image_channels: 1

  use_norm: true
  norm_first: false
  batch_norm {
    momentum: 0.99
    epsilon: 0.0001
  }
  #instance_norm {}

  conv_padding: 'same'

  unet {
    filter_sizes: [64, 128, 256, 512]

    down_activation {
      leaky_relu {
        alpha: 0.2
      }
    }

    up_activation {
      relu {}
    }
  }
}

train_config {
  early_stopping: true
  early_stopping_min_steps: 10000
  early_stopping_max_steps_without_decrease: 30000
  # Runs every n secs if there is a new checkpoint
  early_stopping_run_every_secs: 600
  # Per GPU batch size
  batch_size: 16
  # Weight decay does not work with MirroredStrategy in tf 1.12
  weight_decay: 0.0
  add_regularization_loss: false
  
  data_augmentation_options {random_warp {}}
  #data_augmentation_options {random_horizontal_flip {}}
  #data_augmentation_options {random_vertical_flip {}}
  #data_augmentation_options {
  #  random_brightness {
  #    max_delta: 0.2
  #  }
  #}
  #data_augmentation_options {
  #  random_contrast {
  #    lower: 0.8
  #    upper: 1.25
  #  }
  #}
  #data_augmentation_options {
  #  random_saturation {
  #    lower: 0.8
  #    upper: 1.25
  #  }
  #}
  #data_augmentation_options {
  #  random_hue {
  #    max_delta: 0.02
  #  }
  #}
  
  save_checkpoints_secs: 600
  save_summary_steps: 100
  shuffle: true
  shuffle_buffer_size: 1024
  optimizer {
    adam_optimizer {
      #momentum_optimizer_value: 0.9
      epsilon: 0.1
    }
    learning_rate: {
         exponential_decay_learning_rate {
           initial_learning_rate: 0.0003
           decay_steps: 25000
           decay_factor: 0.96
           staircase: true
         }
         #constant_learning_rate {
         #  learning_rate: 0.0003
         #}
         #manual_step_learning_rate {
         # initial_learning_rate: 0.0003
         # schedule {
         #   step: 0
         #   learning_rate: .0003
         # }
         # schedule {
         #   step: 250000
         #   learning_rate: .00003
         # }
         # schedule {
         #   step: 500000
         #   learning_rate: .00001
         # }
        #}
    }
    # Some bugs in tf DistributionStrategy prevent EMA currently
    use_moving_average: false
    moving_average_decay: 0.9999
  }

  loss {
    name: 'sigmoid'
    use_weighted: true
    weight_constant_add: 0
    weight_constant_multiply: 1
  }
}

eval_config {
  # Currently only a batch size of 1 is supported, because in
  # the region recall metric, the map fn function to split gt masks
  # would result in a shape of [?, ?, x, y]
  batch_size: 1
  eval_interval_secs: 3600
  # If -1 or None will visualize all (i.e. each patient one image)
  num_images_to_visualize: -1
  # Shuffle so that we also get some cancer images in the beginning
  shuffle: true
  shuffle_buffer_size: 1024
  # Dilation of groundtruth just for eval, to reduce FP/FN
  dilate_groundtruth: false
  groundtruth_dilation_kernel_size: 15
}

dataset {
  dataset_path: '/kw_resources/datasets/prostate_images4'
  dataset_info_file: 'patient_assignment_80_15_5_0'
  # 0: 0 - 255
  # 1: 0 - 1
  # 2: -1 - 1
  # This is only important when not scaling input
  val_range: 0
  # Should input have zero mean and unit variance? If true, ignores val_range
  scale_input: true
  balance_classes: false
  # Classes without background
  num_classes: 1
  tfrecords_type: 'regular'

  prostate_cancer {
    only_cancer_images: false
    balance_remove_smallest_patient_set: false
    balance_remove_random_patient_set: false

    dilate_groundtruth: false
    groundtruth_dilation_kernel_size: 11
    
    # For valid padding it should be lower
    common_size_factor: 2
  }
}

seed: 0
